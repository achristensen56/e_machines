{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "hidden1_size = 4\n",
    "hidden2_size = 8\n",
    "fc1_size = 20\n",
    "fc2_size = 10\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "\n",
    "x_ = tf.reshape(x, [-1, 28, 28, 1])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "W_conv1 = weight_variable([3, 3, 1, hidden1_size])\n",
    "b_conv1 = bias_variable([hidden1_size])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "W_conv2 = weight_variable([3, 3, hidden1_size, hidden2_size])\n",
    "b_conv2 = bias_variable([hidden2_size])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "mean1, var1 = tf.nn.moments(h_pool2, axes = [0, 1, 2], keep_dims = False)\n",
    "h_norm = tf.nn.batch_normalization(h_pool2, mean1, var1, 0, .5, 1e-6)\n",
    "\n",
    "W_fc1 = weight_variable([7*7*hidden2_size, fc1_size])\n",
    "b_fc1 = bias_variable([fc1_size])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_norm, [-1, 7*7*hidden2_size])\n",
    "\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "W_fc2 = weight_variable([fc1_size, fc2_size])\n",
    "b_fc2 = bias_variable([fc2_size])\n",
    "\n",
    "y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1]))\n",
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.2\n",
      "step 100, training accuracy 0.78\n",
      "step 200, training accuracy 0.96\n",
      "step 300, training accuracy 0.82\n",
      "step 400, training accuracy 1\n",
      "step 500, training accuracy 0.9\n",
      "step 600, training accuracy 0.96\n",
      "step 700, training accuracy 0.94\n",
      "step 800, training accuracy 0.9\n",
      "step 900, training accuracy 0.96\n",
      "test accuracy 0.9572\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i%100 == 0:\n",
    "        train_accuracy = sess.run(accuracy, feed_dict={\n",
    "        x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    \n",
    "    sess.run(train_step, feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "print(\"test accuracy %g\"%sess.run(accuracy, feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def softmax(x):\n",
    "   \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "   return np.exp(x) / np.sum(np.exp(x), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = sess.run(W_fc2)\n",
    "b = sess.run(b_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[██████████████████████████████] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pyprind\n",
    "\n",
    "data = np.zeros([20,100,10])\n",
    "\n",
    "bar = pyprind.ProgBar(20*100,bar_char='█')\n",
    "for i in range(20):\n",
    "    for j,val in enumerate(np.linspace(-1,1,100)):\n",
    "        bar.update()\n",
    "        x = np.zeros([1,20])\n",
    "        x[0,i]=val\n",
    "        sftmx = softmax(np.squeeze(x.dot(W) + b))\n",
    "        data[i,j,np.argmax(sftmx)]=1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(data[6,:,1])\n",
    "plt.ylabel('activity of neuron 1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "#visualize some training examples\n",
    "num_rows = 5\n",
    "num_cols = 4\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "gs = gridspec.GridSpec(num_rows, num_cols, wspace=0.0)\n",
    "ax = [plt.subplot(gs[i]) for i in range(num_rows*num_cols)]\n",
    "gs.update(hspace=0)\n",
    "gs.tight_layout(fig, h_pad=0,w_pad=0)\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    im = data[i,:,0] \n",
    "    ax[i].plot(im,linewidth=5)  \n",
    "    ax[i].axis('off')\n",
    "\n",
    "plt.show()\n",
    "plt.ylim([-0.1,1.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
